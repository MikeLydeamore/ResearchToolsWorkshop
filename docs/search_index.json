[["index.html", "Reproducibility is you(R) responsibility Chapter 1 Reproducibility and your research 1.1 There isn‚Äôt a silver bullet 1.2 There is more to it than today‚Ä¶ 1.3 Today I will cover‚Ä¶", " Reproducibility is you(R) responsibility Michael Lydeamore 2022-04-21 Chapter 1 Reproducibility and your research Reproducibility is one of the cornerstones of science. It was first introduced to me in high school: ‚ÄúWrite down your methods in a way someone else could repeat them and get the same answer.‚Äù Yet, there is an enormous amount of science that doesn‚Äôt follow that principle. Reproducibility of science is a real problem. Estimates have put the cost in biomedicine alone at more than $28 billion annually1. It‚Äôs not just the financial cost either. Many funding agencies have periods of time in which research must be able to be reproduced. It‚Äôs not just that methods aren‚Äôt fully explained, but implementations are often not shared, or if they are, they don‚Äôt match what is published. I have suffered this myself. Recently, a curious student emailed me about model code from my PhD. Written in MATLAB, a language I haven‚Äôt touched in 6 years, it took me many hours of debugging to get it to run on a modern system. Even then, I doubt I would‚Äôve been able to produce everything in the associated paper without hours of painful work. 1.0.1 Discussion Break out into groups of 2 or 3 and discuss issues and solutions you have seen or used for reproducible research. 1.1 There isn‚Äôt a silver bullet Unfortunately, there isn‚Äôt really a silver bullet to the reproducibility problem. Some people are very good at maintaining strict systems for projects. Some people are less so. Today, we will learn a bit about reproduciblity, and how we can start to build it into our research so we can at least make some progress on what is a big problem. 1.2 There is more to it than today‚Ä¶ We are really just dipping our toe into the water of reproducibility. There is more to consider: Docker, continuous integration, containerisation/virtualisation, and if we want to go even deeper, different computer architectures, long-term data storage and redundancy. You could spend an entire career on this (and people do). But for today, let‚Äôs cover reproducible writing and function-oriented coding, as well as version control, so we can all get a bit better with our research tools. 1.3 Today I will cover‚Ä¶ RStudio and RStudio Projects Avoiding dependency hell with renv Reproducible and automatically updating workflows with targets R markdown structure https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1002165‚Ü©Ô∏é "],["rstudio.html", "Chapter 2 RStudio and RStudio Projects 2.1 RStudio 2.2 RStudio Default Options 2.3 Rstudio Projects 2.4 Projects, with a capital P 2.5 Making sure you‚Äôre in the right place", " Chapter 2 RStudio and RStudio Projects Much of this section is taken from Nick Tierney‚Äôs excellent book R Markdown for Scientists. Here, we will: Look at the structure of an RStudio window, Set some useful default options for RStudio, Create our first RStudio project 2.1 RStudio R is a programming language, like python, or C. One can write R code in whatever they feel like: Notepad, VSCode, punch card (theoretically). But, one of the most popular ways to write R code is using the RStudio IDE. An Integrated Development Environment (IDE) is just a neat program that helps you write code more accurately and faster. RStudio has been around for a long time, and has a lot of R-specific features to help you write solid R code. You should both R and RStudio installed already. If you open RStudio, you‚Äôll be presented with a window something like this: Figure 2.1: A screenshot of the RStudio working environment. Image from https://rmd4sci.njtierney.com/rstudio-what-and-why.html. Top left is the source window - this is where your scripts or markdown files will sit to be edited. Bottom left is the console, where your code is executed. It also has an integrated terminal which can be useful for running certain specific tasks. Top right is the ‚ÄúViewer,‚Äù which has a file browser, plot viewer, help window and a handful of other tabs. If you draw a plot in the console it will appear here for example. Bottom right is the ‚ÄúEnvironment‚Äù pane, which will list all the variables you have loaded currently, the history of your previous commands, and a handful of other things such as version control, build tools and database connections. 2.1.1 Exercise 2.1 Open up the RStudio preferences (Tools &gt; Global Options), and change the layout of your panes! You can arrange them whatever way you like. 2.2 RStudio Default Options RStudio by default is very helpful. It will keep items in your environment if you quit (or crash, usually), and reload them when you re-open RStudio. However, this can be a bit of a reproducibility nightmare. So, we will turn them off. Go to the RStudio preferences (Tools &gt; Global Options), and set the following: Workspace: Uncheck ‚ÄúRestore .Rdata into workspace upon startup‚Äù Save workspace .Rdata on exit: ‚ÄúNever.‚Äù History: Uncheck ‚ÄúRemove duplicate entries in history‚Äù Some people will suggest unchecking ‚ÄúAlways save history (even when not saving .Rdata),‚Äù but I have found personally I rely on history a lot and so not saving that causes more problems than it‚Äôs worth. Your mileage may vary. I‚Äôd also recommend changing the colour scheme to a less retina burning white. My personal favourite is Cobalt currently. 2.3 Rstudio Projects Now that we have our RStudio set up nicely, it‚Äôs time to start work on our project! Not so fast! We should think about how we will arrange our files. A bit of time now will save us a lot of pain later. As someone who has experienced a lot of file management related pain, I cannot stress this enough. 2.3.1 Never use setwd()* *(almost never anyway) It is the least transportable way to set where R is currently looking for files. For example, think about this piece of code: setwd(&quot;/Users/mlyd0001/projects/ResearchToolsWorkshop&quot;) read_csv(&quot;data/mtcars.csv&quot;) This will set the working directory to this workshop, and then load in a CSV I have saved in. Works fine for me. But, what if Mitch would like to work from the same data I‚Äôm using? No problem he can just download my materials and run the script. Error in setwd(&quot;/Users/mlyd0001/projects/ResearchToolsWorkshop&quot;) : cannot change working directory Oh. Why would that be? Well, Mitch isn‚Äôt mlyd0001, and so that folder simply doesn‚Äôt exist on their computer. So straight away, my collaborator will have to go and edit the script, which when they send it back to me, will just error on my end! Perhaps Jenny Bryan feels a bit too strongly about this concept, but: If the first line of your R script is setwd(\"C:\\\\Users\\\\jenny\\\\path\\\\that\\\\only\\\\I\\\\have\") I will come into your office and SET YOUR COMPUTER ON FIRE üî•. And while I won‚Äôt set your computer on fire, I will edit all your code to remove it before I send it back to you, and probably passive-aggressively mention it in my response. 2.3.2 Project structure At the end of the day, how you structure your project is up to you (except for setwd(), that isn‚Äôt up to you). But, we should keep all our files organised in one, top-level folder. My personal structure looks something like this: project_name ‚îî‚îÄ‚îÄ R/ ‚îî‚îÄ‚îÄ various .R files, usually functions ‚îî‚îÄ‚îÄ data/ ‚îî‚îÄ‚îÄ whatever data files I happen to need ‚îî‚îÄ‚îÄ outputs/ ‚îî‚îÄ‚îÄ figures/ ‚îî‚îÄ‚îÄ tables/ ‚îî‚îÄ‚îÄ libraries.R ‚îî‚îÄ‚îÄ pipeline.R If it is, then I will break up pipeline.R into multiple files, to produce the given outputs. But it is critical that the pipeline (or it‚Äôs subfiles) run from top to bottom in a clean R session. The clean R session is important, as it will ensure you‚Äôre not accidentally relying on anything left over in your Environment (remember the option we changed earlier about saving the .Rdata?) and it means that when your collaborator runs the file you know it will run from the top. A handy trick to source all your functions in the pipeline is to use the following: invisible(lapply(list.files(&quot;R/&quot;, pattern = &quot;*.R&quot;, full.names = T), source)) Just remember to re-source if you edit and save. 2.4 Projects, with a capital P So far, we‚Äôve talked about project structure in an ‚Äòinformal‚Äô sense. RStudio takes it a step further, with a formal ‚ÄúProject‚Äù (the P is capitalised on purpose). These projects do a few things: Store project specific settings Project-specific .Rhistory, .Rprofile and a handful of others Add a handy little piece of text on your RStudio icon Store it‚Äôs own history Set your working directory to the project-specific top level folder. They‚Äôre pretty neat. They also come with their own file, ending in .Rproj, which you can open directly to open the project in RStudio instead of loading through the menu. RStudio Projects are specific to RStudio. If you change IDE or choose not to use RStudio, they will not do anything. Other IDEs do have similar concepts: VSCode has ‚Äúworkspaces,‚Äù PyCharm has ‚Äúideas,‚Äù but they are not cross-compatible. 2.4.1 Exercise 2.4 Set up an RStudio Project for this workshop! Go to File &gt; New Project. Usually you‚Äôll be in ‚ÄúNew directory,‚Äù then New project. When you name a project, I think it‚Äôs always worth taking a little bit of time to think of a nice name. For analysis projects (that aren‚Äôt software release based), I tend to just use descriptive names, like ‚ÄúResearchToolsWorkshop.‚Äù Good names will make it easy to find your things years later. The best names apparently: are short do not use spaces cleverly combine words 2.5 Making sure you‚Äôre in the right place While we‚Äôre working in an RStudio Package, it‚Äôs unlikely we‚Äôll need to change our working directory. But it can happen sometimes - maybe we are working on a remote server, or one of our ‚Äúcollaborators‚Äù has left in a pesky setwd() call again. We can ensure we‚Äôre loading data from the right place using the handy package here. The job of here is simple. The function here::here() uses some magic2 to determine where our project root is. Here is my path: here::here() ## [1] &quot;/Users/mlyd0001/projects/ResearchToolsWorkshop&quot; And if I wanted to load some data, I could use here::here(&quot;data/people_who_have_used_setwd.csv&quot;) ## [1] &quot;/Users/mlyd0001/projects/ResearchToolsWorkshop/data/people_who_have_used_setwd.csv&quot; and then no matter how many people have changed working directory on me, here will resolve back to the top-level folder. The extra nice thing about here is that it will work even if we‚Äôre not in an RStudio project. The types of files it searches are more than .Rproj and so it will work in almost all contexts and IDEs. not actually magic, just an algorithm and a specific set of files. See https://github.com/r-lib/rprojroot for more info.‚Ü©Ô∏é "],["renv.html", "Chapter 3 Avoiding dependency hell with renv 3.1 What is dependency hell? 3.2 renv basics and quick-start 3.3 What is a lockfile, anyway? 3.4 Practice time", " Chapter 3 Avoiding dependency hell with renv Here we will: Learn about dependency hell Learn how to avoid dependency hell with renv Set up our own isolated package environment. 3.1 What is dependency hell? Have you ever downloaded someone else‚Äôs code from a long time ago, and it relies on packages for a version of R 12 years ago? Have you then tried to install these old versions of packages only to be met with an error telling you you can‚Äôt downgrade that package because 26 other packages rely on it? (I‚Äôm looking at you rlang) This is what is termed dependency hell. As always, there is an XKCD for that (Figure 3.1). It happens when there is a complex series of dependencies, often many loops, and occasionally different version requirements. R is surprisingly OK with this sort of thing, but if you have a lot of projects (and particularly old ones), then dependency hell can be a real issue. Figure 3.1: As always, there‚Äôs an XKCD for that. Image from https://xkcd.com/1987/. We can avoid dependency hell for our projects by creating isolated, fixed environments for our packages. The RStudio team have developed the package renv to help with exactly that. renv effectively creates a local library for your project, and ensures that libraries are only loaded from that local source, rather than from a single, global source, as is the default. This means that you can have different versions of packages installed for different projects, without any conflicts. 3.2 renv basics and quick-start We start by installing and initialising the project library: install.packages(&quot;renv&quot;) library(renv) renv::init() You will get a message something like: * Initializing project ... * Discovering package dependencies ... Done! * Copying packages into the cache ... Done! Lockfile written to ‚Äò~/projects/ResearchToolsWorkshop/renv.lock.‚Äô Restarting R session‚Ä¶ and there may be a big list of packages that have been detected automatically. From now on, the basic set up is to install a package using renv::install(), just as we would do normally. If installation succeeds, we call renv::snapshot(), and the versions of our packages are saved into the lockfile. If we need to revert our packages, or install somewhere else, we can call renv::restore() and all the packages will be installed (at the correct versions), and we can be on our merry way. 3.3 What is a lockfile, anyway? The lockfile contains all in the information for the packages in the current environment. It is a JSON file, and human readable. Here‚Äôs the entry for the version of knitr used in this book: &quot;knitr&quot;: { &quot;Package&quot;: &quot;knitr&quot;, &quot;Version&quot;: &quot;1.37&quot;, &quot;Source&quot;: &quot;Repository&quot;, &quot;Repository&quot;: &quot;CRAN&quot;, &quot;Hash&quot;: &quot;a4ec675eb332a33fe7b7fe26f70e1f98&quot;, &quot;Requirements&quot;: [ &quot;evaluate&quot;, &quot;highr&quot;, &quot;stringr&quot;, &quot;xfun&quot;, &quot;yaml&quot; ] } There‚Äôs a good amount of information in here. The name of the package, the version, where it came from (CRAN in this case), as well as the dependencies (or ‚Äúrequirements‚Äù). There‚Äôs also a ‚Äúhash,‚Äù which is the md5sum which will be unique to the zip file downloaded as part of the installation process. We don‚Äôt need to worry too much about it, it‚Äôs just another error checking step available. Importantly, because the lockfile is plaintext, it is easily managed in version control. More on that later‚Ä¶ 3.4 Practice time Inside the RStudio Project we made in the previous chapter, let‚Äôs initialise a renv environment. install.packages(&quot;renv&quot;) library(renv) renv::init() renv::install(&quot;tidyverse&quot;) renv::snapshot() "],["targets.html", "Chapter 4 Targets, the make-like pipeline 4.1 Enter targets 4.2 Targets script file 4.3 Defining a target 4.4 Running a pipeline 4.5 Working with a target 4.6 Function-oriented programming 4.7 targets helps you manage complicated workflows 4.8 Extra reading", " Chapter 4 Targets, the make-like pipeline The project structure we discussed in Chapter 2 works fine for our reasonably straightforward projects that don‚Äôt have too many moving parts. Often, our analyses will take a long time to run (I‚Äôm looking at you Stan) or are stochastic (again, Stan), and so we don‚Äôt want to re-run them every time we run our pipeline script. But, we need to make sure everything is up to date if we change something. For example, I‚Äôve plotted my model fit, but mislabelled my axes. I want to re-run the plot but not every step of my analysis. How can I make sure everything is up to date? 4.0.1 Exercise How would you go about keeping only the relevant parts of your script up to date? 4.1 Enter targets Targets borrows it‚Äôs workflow pattern from very old tools like Make, to only run the parts of an analysis that actually need updating. It uses dynamic programming to look at the set of outputs (known as ‚Äútargets‚Äù) and determine if they are outdated, and thus only runs the part of the analysis that needs to be re-run. First, let‚Äôs install targets: install.packages(&quot;targets&quot;) install.packages(&quot;visNetwork&quot;) library(targets) Annoyingly, targets relies on igraph to do a lot of it‚Äôs graph-related work both to visualise the pipeline and work out what is connected to what. igraph is a very large, very heavy package so give it a few minutes to install. We also install visNetwork as that will give us some pretty visualisations shortly. Every targets workflow needs a special _targets.R file. We can create that by running: targets::use_targets() targets::tar_edit() and actually, we can use that second command to edit the this file from anywhere, so it can be useful to bind it to a key. 4.2 Targets script file After creating, your _targets.R file will look something like this: # Created by use_targets(). # Follow the comments below to fill in this target script. # Then follow the manual to check and run the pipeline: # https://books.ropensci.org/targets/walkthrough.html#inspect-the-pipeline # nolint # Load packages required to define the pipeline: library(targets) # library(tarchetypes) # Load other packages as needed. # nolint # Set target options: tar_option_set( packages = c(&quot;tibble&quot;), # packages that your targets need to run format = &quot;rds&quot; # default storage format # Set other options as needed. ) # tar_make_clustermq() configuration (okay to leave alone): options(clustermq.scheduler = &quot;multicore&quot;) # tar_make_future() configuration (okay to leave alone): # Install packages {{future}}, {{future.callr}}, and {{future.batchtools}} to allow use_targets() to configure tar_make_future() options. # Load the R scripts with your custom functions: for (file in list.files(&quot;R&quot;, full.names = TRUE)) source(file) # source(&quot;other_functions.R&quot;) # Source other scripts as needed. # nolint # Replace the target list below with your own: list( tar_target( name = data, command = tibble(x = rnorm(100), y = rnorm(100)) # format = &quot;feather&quot; # efficient storage of large data frames # nolint ), tar_target( name = model, command = coefficients(lm(y ~ x, data = data)) ) ) There‚Äôs a bit going on here. The first point of difference from a typical workflow is that instead of loading packages with library, we set them inside tar_option_set. This is because targets runs in a fresh R session (not your current one!) and will load those packages into each session separately. The next few lines are focussed on running targets in parallel - helpful but outside the scope for today. Then, there is a one-liner that will source all the files in your ‚ÄúR‚Äù subdirectory. Finally, there‚Äôs a list of targets, and this is the juicy part‚Ä¶ 4.3 Defining a target All targets must start with a call to tar_target(). This function takes two arguments: A name for the target (call it whatever you like, but make it memorable) A command to run. This can be any valid R expression, but the targets authors suggest following functional programming. More on this a bit later. The example file has two targets. One generates some data, and the second fits a linear model to said data. We can see how this works by calling: tar_visnetwork() We can see our 2 functions, and the object file, which is produced by the code which will source our R files. The graph shows us that data feeds into the model. 4.4 Running a pipeline Running the targets pipeline is straightforward3 tar_make() ## ‚Ä¢ start target data ## ‚Ä¢ built target data ## ‚Ä¢ start target model ## ‚Ä¢ built target model ## ‚Ä¢ end pipeline: 0.045 seconds There‚Äôs a bit of output telling you what gets built and what gets skipped. The first time you run a pipeline, everything will have to be made, but from then on, only the outdated bits will be run: tar_make() ## ‚úì skip target data ## ‚úì skip target model ## ‚úì skip pipeline: 0.031 seconds 4.5 Working with a target Once your targets are built, you might want to do something with them. For interactive programming (which includes markdown), we can load the target into our current environment using tar_load(). For example, tar_load(model) model ## (Intercept) x ## 0.01023539 0.09225038 We can also just print the current value (useful for plots) with tar_read(). Note that you only need to tar_load or tar_read outside of the targets workflow. If you‚Äôre writing a function to use an input, do not use these functions, just use the input argument as you normally would, and pass in the name of the target inside the _targets.R file. For example, if we wanted a function that worked with our coefficients we would write: transform_slope &lt;- function(coefficients, multiplier) { coefficients[2] * multiplier # Note the lack of tar_load() here! } and then add the following to the end of the _targets.R file: tar_target( transformed_slope, transform_slope(model, 3) ) 4.5.1 Exercise Try adding these features to your targets pipeline and get it to run. 4.6 Function-oriented programming Technically speaking, tar_target will accept any valid R expression. Theoretically, this means we never need to write another R function ever again! But, if we do that, we‚Äôll quickly find our _targets.R file will be incredibly long. Consider this example from the targets manual: library(targets) source(&quot;R/functions.R&quot;) tar_option_set(packages = c(&quot;tibble&quot;, &quot;readr&quot;, &quot;dplyr&quot;, &quot;ggplot2&quot;)) list( tar_target(file, &quot;data.csv&quot;, format = &quot;file&quot;), tar_target( data, read_csv(file, col_types = cols()) %&gt;% filter(!is.na(Ozone)) ), tar_target( model, lm(Ozone ~ Temp, data) %&gt;% coefficients() ), tar_target( plot, ggplot(data) + geom_point(aes(x = Temp, y = Ozone)) + geom_abline(intercept = model[1], slope = model[2]) + theme_gray(24) ) ) With only three, relatively simple targets, this file is already 18 lines long. If we instead write each of these targets as their own functions, we can reduce this file to library(targets) source(&quot;R/functions.R&quot;) tar_option_set(packages = c(&quot;tibble&quot;, &quot;readr&quot;, &quot;dplyr&quot;, &quot;ggplot2&quot;)) list( tar_target(file, &quot;data.csv&quot;, format = &quot;file&quot;), tar_target(data, get_data(file)), tar_target(model, fit_model(data)), tar_target(plot, plot_model(model, data)) ) Much cleaner. This makes us write a function for every step in our process, which makes long-term maintenance of code a lot easier. It might seem cludgy at first (it was to me), but over time it has led my code to be cleaner and easier to adjust going forward. I also recommend the rather nice fnmate package (only available on GitHub) to make writing functions easier as it will auto-generate the skeletons for you. 4.7 targets helps you manage complicated workflows Here is a more complicated workflow from one of my projects: You can see how if I update a function somewhere in the middle, it‚Äôs not immediately obvious to me what needs to be updated and when, yet targets will handle all of this for me. Truly one of my favourite packages. 4.8 Extra reading The user manual for targets is quite good. tarchetypes is another good package that makes targets a bit nicer to work with. one shouldn‚Äôt call tar_make() inside an Rmd document, as it will get called every time you knit, which isn‚Äôt really ideal.‚Ü©Ô∏é "],["rmarkdown.html", "Chapter 5 RMarkdown basics 5.1 What is RMarkdown? 5.2 The traditional writing process 5.3 Enter RMarkdown 5.4 Exercise", " Chapter 5 RMarkdown basics Here, we will: Learn what an RMarkdown document is Write some markdown and combine it with R code Compile to HTML, PDF and Word 5.1 What is RMarkdown? To understand the purpose pf RMarkdown, we should first take a look at the ‚Äútraditional‚Äù scientific writing process. 5.2 The traditional writing process Usually, you will load the data, write the scripts to do the analysis, save some figures, and get to writing. If you‚Äôre a mathematician or computer scientist, you‚Äôll write in LaTeX, if you‚Äôre not you‚Äôll probably use Word. When you write out your tables, if you‚Äôre like me, you‚Äôll painstakingly copy/paste numbers from the console into the document, and hope you get the row right. Then, when your work is done, and the reviews come back, they‚Äôve asked you to add a term to the model. No problem, you say. You add your model term, update the tables, resubmit, ba da bing, ba da boom. Except you forgot the figure! Sigh. 5.3 Enter RMarkdown Markdown is a basic ‚Äúmarkup‚Äù language. You write plain text, and a compiler will convert it into HTML for display. RMarkdown combines R with markdown, and allows you to embed code into your writing. It‚Äôs the future! Now, you can write your paper and include the code to make the figures or the models, and then when Reviewer 2 comes and asks for an extra term, nothing will be forgotten. RMarkdown could be considered literate programming. That is, the combination of literature and programming, a concept first introduced by Donald Knuth. RMarkdown documents can be compiled into HTML, PDF or Word documents. I recommend working with HTML for now, spending time messing about with Word and PDF formatting tends to be wasted time unless the document is almost final. We‚Äôll spend a lot more time today about RMarkdown, but for now, let‚Äôs compile a little document of our own. --- title: &quot;Plotting mtcars&quot; author: &quot;Michael Lydeamore&quot; output: html_document --- `mtcars` is a dataset included with R, characterising the fuel efficiencies of cars with some covariates. ```r head(mtcars) plot(mtcars$mpg, mtcars$cyl) ``` This should produce a small report that looks something like this: 5.4 Exercise Copy the above RMarkdown code into a blank document, and ‚ÄúKnit‚Äù to HTML, PDF and Word. If you get an error compiling to PDF, you might have to install the tinytex package. "]]
